#!/usr/bin/env python3
"""
æ£€æµ‹å¸§å”¯ä¸€æ€§çš„æµ‹è¯•å·¥å…·
åˆ†ææ˜¯å¦å­˜åœ¨é‡å¤æˆ–è¿‡äºç›¸ä¼¼çš„å¸§æ•°æ®
"""
import time
import requests
import json
import base64
import gzip
import numpy as np
from datetime import datetime
from collections import deque

def decompress_fft_data(compressed_data):
    """è§£å‹ç¼©FFTæ•°æ®"""
    try:
        binary_string = base64.b64decode(compressed_data)
        decompressed = gzip.decompress(binary_string)
        return np.frombuffer(decompressed, dtype=np.float32)
    except Exception as e:
        print(f"âŒ è§£å‹ç¼©å¤±è´¥: {e}")
        return None

def calculate_frame_similarity(data1, data2):
    """è®¡ç®—ä¸¤å¸§æ•°æ®çš„ç›¸ä¼¼åº¦(0-1, 1è¡¨ç¤ºå®Œå…¨ç›¸åŒ)"""
    if data1 is None or data2 is None or len(data1) != len(data2):
        return 0.0
    
    # è®¡ç®—ç›¸å…³ç³»æ•°
    correlation = np.corrcoef(data1, data2)[0, 1]
    if np.isnan(correlation):
        return 0.0
    
    # è®¡ç®—å‡æ–¹æ ¹è¯¯å·®çš„å½’ä¸€åŒ–ç‰ˆæœ¬
    mse = np.mean((data1 - data2) ** 2)
    max_possible_mse = np.mean(data1 ** 2) + np.mean(data2 ** 2)
    if max_possible_mse == 0:
        return 1.0
    
    normalized_mse = mse / max_possible_mse
    mse_similarity = 1.0 - min(normalized_mse, 1.0)
    
    # ç»¼åˆç›¸å…³ç³»æ•°å’ŒMSE
    return (abs(correlation) + mse_similarity) / 2.0

def test_frame_uniqueness():
    print("ğŸ” æµ‹è¯•å¸§æ•°æ®å”¯ä¸€æ€§å’Œå˜åŒ–ç¨‹åº¦")
    print("=" * 60)
    
    url = "http://localhost:8380/api/stream"
    
    try:
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()
        
        frame_count = 0
        start_time = time.time()
        
        # ä¿å­˜æœ€è¿‘çš„å‡ å¸§æ•°æ®ç”¨äºæ¯”è¾ƒ
        recent_frames = deque(maxlen=5)
        duplicate_count = 0
        high_similarity_count = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        similarities = []
        peak_frequencies = []
        magnitude_ranges = []
        
        print("æ­£åœ¨åˆ†æå¸§æ•°æ®...")
        print("æ ¼å¼: [æ—¶é—´] å¸§å· | ç›¸ä¼¼åº¦ | å³°å€¼é¢‘ç‡ | å¹…åº¦èŒƒå›´ | çŠ¶æ€")
        print("-" * 80)
        
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                
                if line.startswith('data: '):
                    try:
                        data_json = line[6:]
                        data = json.loads(data_json)
                        
                        # è·³è¿‡éFFTæ•°æ®
                        if 'type' in data or 'data_compressed' not in data:
                            continue
                        
                        # è§£å‹ç¼©FFTæ•°æ®
                        fft_data = decompress_fft_data(data['data_compressed'])
                        if fft_data is None:
                            continue
                        
                        frame_count += 1
                        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
                        
                        # è®¡ç®—å½“å‰å¸§çš„ç»Ÿè®¡ä¿¡æ¯
                        peak_freq = data.get('peak_frequency_hz', 0) / 1000  # kHz
                        magnitude_min = np.min(fft_data)
                        magnitude_max = np.max(fft_data)
                        magnitude_range = magnitude_max - magnitude_min
                        
                        peak_frequencies.append(peak_freq)
                        magnitude_ranges.append(magnitude_range)
                        
                        # ä¸æœ€è¿‘çš„å¸§æ¯”è¾ƒç›¸ä¼¼åº¦
                        status = "æ–°å¸§"
                        max_similarity = 0.0
                        
                        if recent_frames:
                            similarities_with_recent = []
                            for prev_data, prev_info in recent_frames:
                                similarity = calculate_frame_similarity(fft_data, prev_data)
                                similarities_with_recent.append(similarity)
                            
                            max_similarity = max(similarities_with_recent)
                            similarities.append(max_similarity)
                            
                            if max_similarity > 0.99:
                                duplicate_count += 1
                                status = "ğŸ”´ é‡å¤å¸§"
                            elif max_similarity > 0.95:
                                high_similarity_count += 1
                                status = "ğŸŸ¡ é«˜ç›¸ä¼¼"
                            elif max_similarity > 0.8:
                                status = "ğŸŸ¢ æ­£å¸¸å˜åŒ–"
                            else:
                                status = "ğŸ”µ å¤§å¹…å˜åŒ–"
                        
                        # ä¿å­˜å½“å‰å¸§
                        recent_frames.append((fft_data, {
                            'peak_freq': peak_freq,
                            'magnitude_range': magnitude_range,
                            'timestamp': time.time()
                        }))
                        
                        # æ¯10å¸§æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†ä¿¡æ¯
                        if frame_count % 10 == 0:
                            print(f"[{timestamp}] #{frame_count:3d} | "
                                  f"ç›¸ä¼¼åº¦:{max_similarity:.3f} | "
                                  f"å³°å€¼:{peak_freq:6.1f}kHz | "
                                  f"èŒƒå›´:{magnitude_range:6.1f}dB | "
                                  f"{status}")
                        
                        # å½“è¾¾åˆ°ä¸€å®šå¸§æ•°æ—¶æ˜¾ç¤ºç»Ÿè®¡æŠ¥å‘Š
                        if frame_count == 100:
                            print("\n" + "="*60)
                            print("ğŸ“Š 100å¸§ç»Ÿè®¡æŠ¥å‘Š:")
                            if similarities:
                                avg_similarity = np.mean(similarities)
                                print(f"   å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}")
                                print(f"   é‡å¤å¸§æ•°: {duplicate_count} ({duplicate_count/frame_count*100:.1f}%)")
                                print(f"   é«˜ç›¸ä¼¼å¸§æ•°: {high_similarity_count} ({high_similarity_count/frame_count*100:.1f}%)")
                            
                            if peak_frequencies:
                                freq_std = np.std(peak_frequencies)
                                print(f"   å³°å€¼é¢‘ç‡æ ‡å‡†å·®: {freq_std:.2f} kHz")
                            
                            if magnitude_ranges:
                                range_std = np.std(magnitude_ranges)
                                print(f"   å¹…åº¦èŒƒå›´æ ‡å‡†å·®: {range_std:.2f} dB")
                            
                            print("="*60)
                            print("ç»§ç»­ç›‘æ§...")
                        
                        # é™åˆ¶æµ‹è¯•æ—¶é—´
                        if time.time() - start_time > 15:  # 15ç§’ååœæ­¢
                            break
                            
                    except json.JSONDecodeError:
                        continue
                    except Exception as e:
                        print(f"âŒ å¤„ç†é”™è¯¯: {e}")
                        continue
                        
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¿æ¥é”™è¯¯: {e}")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•ä¸­æ–­")
        
    finally:
        if frame_count > 0:
            print(f"\nğŸ“‹ æœ€ç»ˆç»Ÿè®¡:")
            print(f"   æ€»å¸§æ•°: {frame_count}")
            print(f"   é‡å¤å¸§: {duplicate_count} ({duplicate_count/frame_count*100:.1f}%)")
            print(f"   é«˜ç›¸ä¼¼å¸§: {high_similarity_count} ({high_similarity_count/frame_count*100:.1f}%)")
            
            if similarities:
                print(f"   å¹³å‡å¸§é—´ç›¸ä¼¼åº¦: {np.mean(similarities):.3f}")
                print(f"   ç›¸ä¼¼åº¦æ ‡å‡†å·®: {np.std(similarities):.3f}")
            
            if len(peak_frequencies) > 1:
                print(f"   å³°å€¼é¢‘ç‡å˜åŒ–: {np.std(peak_frequencies):.2f} kHz")
            
            if len(magnitude_ranges) > 1:
                print(f"   å¹…åº¦èŒƒå›´å˜åŒ–: {np.std(magnitude_ranges):.2f} dB")
                
            # åˆ¤æ–­é—®é¢˜æ‰€åœ¨
            if duplicate_count / frame_count > 0.3:
                print("\nâš ï¸  æ£€æµ‹åˆ°å¤§é‡é‡å¤å¸§ï¼è¿™å¯èƒ½æ˜¯å¯¼è‡´è§†è§‰ä¸æµç•…çš„åŸå› ã€‚")
            elif np.mean(similarities) > 0.9:
                print("\nâš ï¸  å¸§é—´ç›¸ä¼¼åº¦è¿‡é«˜ï¼å¯èƒ½ç¼ºä¹è¶³å¤Ÿçš„æ•°æ®å˜åŒ–ã€‚")
            elif np.std(peak_frequencies) < 0.1:
                print("\nâš ï¸  éŸ³é¢‘ä¿¡å·å˜åŒ–å¾ˆå°ï¼å¯èƒ½ç¯å¢ƒè¿‡äºå®‰é™ã€‚")
            else:
                print("\nâœ… å¸§æ•°æ®çœ‹èµ·æ¥æ­£å¸¸ï¼Œé—®é¢˜å¯èƒ½åœ¨å…¶ä»–åœ°æ–¹ã€‚")

if __name__ == "__main__":
    test_frame_uniqueness()